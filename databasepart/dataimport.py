import pandas as pd
import urllib.request
import os
import urllib.request
import gzip
import shutil

def download_imdb_data_smart(force_redownload=False):
    """
    æ™ºèƒ½ä¸‹è½½IMDbæ•°æ®

    Args:
        force_redownload (bool): æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
    """
    base_url = "https://datasets.imdbws.com/"
    files = [
        "title.basics.tsv.gz",
        "title.ratings.tsv.gz",
        "title.crew.tsv.gz",
        "title.principals.tsv.gz",
        "name.basics.tsv.gz"
    ]

    downloaded_count = 0
    skipped_count = 0

    for file in files:
        gz_file = file
        extracted_file = file.replace('.gz', '')

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å¤„ç†
        if not force_redownload and os.path.exists(extracted_file):
            file_size = os.path.getsize(extracted_file)
            if file_size > 1000:  # æ–‡ä»¶å¤§å°åˆç†ï¼ˆå¤§äº1KBï¼‰
                print(f"âœ… è·³è¿‡ {extracted_file} (æ–‡ä»¶å·²å­˜åœ¨, {file_size:,} bytes)")
                skipped_count += 1
                continue

        # ä¸‹è½½å‹ç¼©æ–‡ä»¶ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if force_redownload or not os.path.exists(gz_file):
            print(f"â¬‡ï¸  ä¸‹è½½ {file}...")
            try:
                urllib.request.urlretrieve(base_url + file, gz_file)
                gz_size = os.path.getsize(gz_file)
                print(f"âœ… ä¸‹è½½å®Œæˆ: {file} ({gz_size:,} bytes)")
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
                continue
        else:
            print(f"ğŸ“¦ ä½¿ç”¨ç°æœ‰å‹ç¼©æ–‡ä»¶: {gz_file}")

        # è§£å‹æ–‡ä»¶
        print(f"ğŸ”§ è§£å‹ {gz_file}...")
        try:
            with gzip.open(gz_file, 'rb') as f_in:
                with open(extracted_file, 'wb') as f_out:
                    shutil.copyfileobj(f_in, f_out)

            extracted_size = os.path.getsize(extracted_file)
            print(f"âœ… è§£å‹å®Œæˆ: {extracted_file} ({extracted_size:,} bytes)")
            downloaded_count += 1

        except Exception as e:
            print(f"âŒ è§£å‹å¤±è´¥: {e}")
            # åˆ é™¤å¯èƒ½æŸåçš„æ–‡ä»¶
            if os.path.exists(extracted_file):
                os.remove(extracted_file)

    print(f"\nğŸ“Š æ€»ç»“: ä¸‹è½½äº† {downloaded_count} ä¸ªæ–‡ä»¶, è·³è¿‡äº† {skipped_count} ä¸ªå·²å­˜åœ¨æ–‡ä»¶")

def clean_imdb_data(df):
    """
    ä¸“é—¨æ¸…ç†IMDbæ•°æ®çš„å‡½æ•°
    """
    print("å¼€å§‹æ¸…ç†IMDbæ•°æ®...")
    print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")

    # 1. æ›¿æ¢æ‰€æœ‰ \N ä¸º NaN
    df_clean = df.replace('\\N', pd.NA)

    # 2. æ˜¾ç¤ºæ¸…ç†å‰çš„ç©ºå€¼æƒ…å†µ
    print("\næ¸…ç†å‰ç©ºå€¼ç»Ÿè®¡:")
    null_summary = df_clean.isna().sum()
    for col, null_count in null_summary.items():
        if null_count > 0:
            print(f"  {col}: {null_count} ä¸ªç©ºå€¼")

    # 3. åˆ é™¤æ‰€æœ‰åŒ…å«ç©ºå€¼çš„è¡Œ
    df_clean = df_clean.dropna()

    # 4. é‡ç½®ç´¢å¼•
    df_clean = df_clean.reset_index(drop=True)

    print(f"\næ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")
    print(f"åˆ é™¤äº† {len(df) - len(df_clean)} è¡Œæ•°æ®")

    return df_clean

def load_imdb_data(show_movies_head = False, show_movies_type = False, show_rating_range = False):
    # åŠ è½½ç”µå½±åŸºæœ¬ä¿¡æ¯
    movies_df = pd.read_csv('title.basics.tsv', sep='\t', low_memory=False)
    movies_df = movies_df[movies_df['titleType'] == 'movie']
    # åŠ è½½è¯„åˆ†ä¿¡æ¯
    ratings_df = pd.read_csv('title.ratings.tsv', sep='\t')
    # åˆå¹¶æ•°æ®
    movies_with_ratings = pd.merge(movies_df, ratings_df, on='tconst', how='inner')
    # è¿›è¡Œæ•°æ®æ¸…æ´—
    movies_with_ratings.drop('titleType', axis=1, inplace=True)
    movies_with_ratings.drop('originalTitle', axis=1, inplace=True)
    movies_with_ratings.drop('endYear', axis=1, inplace=True)
    movies_with_ratings = clean_imdb_data(movies_with_ratings)
    # æ•°æ®ç±»å‹è½¬æ¢
    movies_with_ratings['startYear'] = pd.to_numeric(movies_with_ratings['startYear'])
    movies_with_ratings['runtimeMinutes'] = pd.to_numeric(movies_with_ratings['runtimeMinutes'])
    if show_movies_head:
        print(movies_with_ratings.head())
    if show_movies_type:
        print(movies_with_ratings.info())
    if show_rating_range:
        print(movies_with_ratings['averageRating'].min())
        print(movies_with_ratings['averageRating'].max())
    return movies_with_ratings

def main():
    # æ°¸ä¹…è®¾ç½®æ˜¾ç¤ºé€‰é¡¹ï¼ˆåœ¨å½“å‰ä¼šè¯ä¸­æœ‰æ•ˆï¼‰
    pd.set_option('display.max_columns', None)
    pd.set_option('display.max_rows', None)
    pd.set_option('display.max_colwidth', None)
    pd.set_option('display.width', None)
    # ä¸‹è½½æ•°æ®
    force_redownload = False  # æ˜¯å¦å¼ºåˆ¶ä¸‹è½½
    download_imdb_data_smart(force_redownload)
    # ä½¿ç”¨æ•°æ®
    show_movies_head = True
    show_movies_type = False
    show_rating_range = False
    movies_data = load_imdb_data(show_movies_head, show_movies_type, show_rating_range)  # éœ€è¦å•ç‹¬å»ºè¡¨movie

    principals_data = pd.read_csv('title.principals.tsv', sep='\t')
    principals_data = principals_data[principals_data['tconst'].isin(movies_data['tconst'])]
    principals_data.drop('job', axis=1, inplace=True)
    principals_data.drop('characters', axis=1, inplace=True)
    principals_data.reset_index(drop=True, inplace=True)
    test_nan = False # å¯¹è¡¨ä¸­æ˜¯å¦æœ‰nanè¿›è¡Œæµ‹è¯•å’Œæ¸…æ´—
    if test_nan:
        principals_data = clean_imdb_data(principals_data)
    print(principals_data.head(10))

    name_data = pd.read_csv('name.basics.tsv', sep='\t', low_memory=False)
    name_data = name_data[name_data['nconst'].isin(principals_data['nconst'])]
    name_data.drop('primaryProfession', axis=1, inplace=True)
    name_data.drop('knownForTitles', axis=1, inplace=True)
    name_data.reset_index(drop=True, inplace=True)
    # é€‰æ‹©é™¤ deathYear å¤–çš„æ‰€æœ‰åˆ—
    columns_to_check = [col for col in name_data.columns if col != 'deathYear' and col != 'birthYear']
    # æ£€æµ‹è¿™äº›åˆ—ä¸­æ˜¯å¦å­˜åœ¨ \N
    has_backslash_n = name_data[columns_to_check].eq('\\N').any().any()
    print(f"é™¤deathYearå¤–å…¶ä»–åˆ—æ˜¯å¦å­˜åœ¨ \\N: {has_backslash_n}")
    if has_backslash_n:
        # æ‰¾å‡ºåœ¨æŒ‡å®šåˆ—ä¸­åŒ…å« \N çš„è¡Œ
        mask = name_data[columns_to_check].eq('\\N').any(axis=1)
        rows_with_backslash_n = name_data[mask]

        print("\nåŒ…å« \\N çš„è¡Œæ•°æ®:")
        print(rows_with_backslash_n)
    print(name_data.head())

if __name__ == "__main__":
    main()
